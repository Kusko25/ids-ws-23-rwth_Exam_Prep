{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Q10\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "data = \"\"\"Event ID, Case ID, Activity, Timestamp\n",
    "e1 x1 a 1\n",
    "e2 x1 c 4\n",
    "e3 x2 a 1\n",
    "e4 x2 b 2\n",
    "e5 x1 b 2\n",
    "e6 x2 c 4\n",
    "e7 x1 b 3\"\"\"\n",
    "data = data.splitlines()\n",
    "columns = data[0].split(\", \")\n",
    "data = [i.split() for i in data[1:]]\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "df = df.astype({\"Timestamp\": int})\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (a)\n",
    "df_a = df.copy()\n",
    "\n",
    "def map_step(entry:tuple) -> list[int, list[tuple]]:\n",
    "    return entry[2], entry\n",
    "\n",
    "def reduce_step(key, values:list[tuple]):\n",
    "    # Index row is also present so activity is at 3 and timestamp at 4\n",
    "    activities = [(row[3],row[4]) for row in values]\n",
    "    activities = sorted(activities,key=lambda x:int(x[1]))\n",
    "    return key,(x[0] for x in activities)\n",
    "\n",
    "def map_reduce(df):\n",
    "    map_dict = dict()\n",
    "    for row in df.itertuples():\n",
    "        key,values = map_step(row)\n",
    "        if key in map_dict:\n",
    "            map_dict[key].append(values)\n",
    "        else:\n",
    "            map_dict[key] = [values]\n",
    "    results = list()\n",
    "    for key in map_dict:\n",
    "        results.append(reduce_step(key,map_dict[key]))\n",
    "    return results\n",
    "\n",
    "for result in map_reduce(df_a):\n",
    "    print(result[0],list(result[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) Come on this is barely Big Data related it's just an algorithm (of many) in the BigData area not a central concept\n",
    "# !!!! That being said what follows is ALL WRONG, see next cell for proper implementation\n",
    "# Cluster assignment happens based on distance\n",
    "# so all points get assigned to c1 in the first step\n",
    "# New centroids are computed as \n",
    "# sum(w_c*c,other_points)/(w_c+len(other_points))\n",
    "# I don't actually know if alpha*w_c gets executed before or after\n",
    "# but I assume after.\n",
    "alpha = 0.5\n",
    "c1 = np.array((0,0))\n",
    "w_c1 = 1.0\n",
    "c2 = np.array((10,10))\n",
    "w_c2 = 1.0\n",
    "def step(new_instances,alpha,c1,w_c1,c2,w_c2):\n",
    "    cluster1 = []\n",
    "    cluster2 = []\n",
    "    for point in new_instances:\n",
    "        if np.linalg.norm(c1-point) > np.linalg.norm(c2-point):\n",
    "            cluster2.append(point)\n",
    "        else:\n",
    "            cluster1.append(point)\n",
    "    new_c1 = (sum(cluster1)+w_c1*c1)/(len(cluster1)+w_c1)\n",
    "    new_c2 = (sum(cluster2)+w_c2*c2)/(len(cluster2)+w_c2)\n",
    "    return new_c1,alpha*w_c1,new_c2,alpha*w_c2\n",
    "\n",
    "new_instances = np.array(\n",
    "    [\n",
    "        (3,3),\n",
    "        (-3,3),\n",
    "        (1,3),\n",
    "        (-1,0)\n",
    "    ]\n",
    ")\n",
    "c1,w_c1,c2,w_c2 = step(new_instances,alpha,c1,w_c1,c2,w_c2)\n",
    "display(c1,w_c1,c2,w_c2)\n",
    "\n",
    "c1,w_c1,c2,w_c2 = step(new_instances,alpha,c1,w_c1,c2,w_c2)\n",
    "display(c1,w_c1,c2,w_c2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (b) \n",
    "alpha = 0.5\n",
    "c1 = np.array((0,0))\n",
    "w_c1 = 1.0\n",
    "c2 = np.array((10,10))\n",
    "w_c2 = 1.0\n",
    "\n",
    "threshold = 0.8\n",
    "\n",
    "new_instances = np.array(\n",
    "    [\n",
    "        (3,3),\n",
    "        (-3,3),\n",
    "        (1,3),\n",
    "        (-1,0)\n",
    "    ]\n",
    ")\n",
    "\n",
    "def step(new_instances,alpha,c1,w_c1,c2,w_c2):\n",
    "    cluster1 = []\n",
    "    cluster2 = []\n",
    "    for point in new_instances:\n",
    "        if np.linalg.norm(c1-point) > np.linalg.norm(c2-point):\n",
    "            cluster2.append(point)\n",
    "        else:\n",
    "            cluster1.append(point)\n",
    "    new_c1 = (sum(cluster1)*len(cluster1)+alpha*w_c1*c1)/(len(cluster1)+(alpha*w_c1))\n",
    "    new_c2 = (sum(cluster2)*len(cluster2)+alpha*w_c2*c2)/(len(cluster2)+(alpha*w_c2))\n",
    "    return new_c1,alpha*w_c1+len(cluster1),new_c2,alpha*w_c2+len(cluster2)\n",
    "\n",
    "\n",
    "c1,w_c1,c2,w_c2 = step(new_instances,alpha,c1,w_c1,c2,w_c2)\n",
    "print(f\"New Centroid 1 at ({c1[0]:.2f},({c1[1]:.2f}) with weight {w_c1:.2f}\")\n",
    "print(f\"New Centroid 2 at ({c2[0]:.2f},({c2[1]:.2f}) with weight {w_c2:.2f}\")\n",
    "\n",
    "if w_c1 < threshold:\n",
    "    print(\"Cluster 1 is subcritical. Kick it out.\")\n",
    "\n",
    "if w_c2 < threshold:\n",
    "    print(\"Cluster 2 is subcritical. Kick it out.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ids-ws23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
