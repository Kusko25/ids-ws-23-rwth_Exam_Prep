{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from random import randint, random\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighbors(x, y, grid):\n",
    "    neighbors = []\n",
    "    dim_x, dim_y = grid.shape\n",
    "    for i,j in [(-1,0),(1,0),(0,-1),(0,1)]:\n",
    "        if i == j == 0:\n",
    "            continue\n",
    "        if 0 <= x + i < dim_x and 0 <= y + j < dim_y:\n",
    "            neighbors.append((x + i, y + j))\n",
    "    return neighbors\n",
    "\n",
    "def has_neighbor_with_value(x, y, value, grid):\n",
    "    for neighbor in get_neighbors(x, y, grid):\n",
    "        if grid[neighbor] == value:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def print_grid(grid):\n",
    "    for row in grid:\n",
    "        print(\"\".join(str(int(x)) for x in row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_x = 15//3\n",
    "dim_y = 20//3\n",
    "grid = np.zeros((dim_x, dim_y))\n",
    "activation = 0.2\n",
    "spread = 10\n",
    "\n",
    "\n",
    "# Seed\n",
    "# grid[randint(0, dim_x - 1), randint(0, dim_y - 1)] = 1\n",
    "\n",
    "# for _ in range(spread):\n",
    "#     grid_copy = grid.copy()\n",
    "#     for x,y in np.ndindex(grid.shape):\n",
    "#         if grid_copy[x, y] == 0 and has_neighbor_with_value(x, y, 1, grid) and random() < activation:\n",
    "#             grid_copy[x, y] = 1\n",
    "#     grid = grid_copy\n",
    "\n",
    "grid=[\n",
    "    [0,0,0,0,0,0,0,0,0,0],\n",
    "    [0,0,0,0,0,0,0,1,0,0],\n",
    "    [0,0,0,0,0,0,0,1,1,1],\n",
    "    [0,0,0,1,1,0,0,0,0,1],\n",
    "    [0,0,0,1,1,0,0,0,1,1],\n",
    "    [0,0,1,1,0,1,1,1,1,1],\n",
    "    [0,0,0,1,1,1,1,1,1,1],\n",
    "    [0,0,0,0,1,1,1,1,1,1],\n",
    "    [0,0,0,0,0,1,1,1,1,1],\n",
    "    [0,0,0,0,0,1,1,1,1,1]\n",
    "]\n",
    "grid = [row[::-1] for row in grid]\n",
    "dim_x, dim_y = len(grid), len(grid[0])\n",
    "\n",
    "# print_grid(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = (-1, 2)\n",
    "y_range = (-2, 2)\n",
    "\n",
    "def cord_to_value(x, y):\n",
    "    return grid[int((x - x_range[0]) / (x_range[1] - x_range[0]) * dim_x)][int((y - y_range[0]) / (y_range[1] - y_range[0]) * dim_y)]\n",
    "\n",
    "x,y,z = [],[],[]\n",
    "n_cords = 100\n",
    "for _ in range(n_cords):\n",
    "    x.append(random() * (x_range[1] - x_range[0]) + x_range[0])\n",
    "    y.append(random() * (y_range[1] - y_range[0]) + y_range[0])\n",
    "    z.append(cord_to_value(x[-1], y[-1]))\n",
    "\n",
    "df = pd.DataFrame({\"x\": x, \"y\": y, \"InSet\": [bool(z) for z in z]})\n",
    "display(df.value_counts(\"InSet\"))\n",
    "sns.scatterplot(x=x, y=y, hue=z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df_lr = df.copy()\n",
    "LogisticRegression().fit(df_lr[[\"x\", \"y\"]], df_lr[\"InSet\"]).score(df_lr[[\"x\", \"y\"]], df_lr[\"InSet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM (no kernel)\n",
    "from sklearn.svm import SVC\n",
    "df_svm = df.copy()\n",
    "SVC(kernel=\"linear\").fit(df_svm[[\"x\", \"y\"]], df_svm[\"InSet\"]).score(df_svm[[\"x\", \"y\"]], df_svm[\"InSet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## SVM (with kernel)\n",
    "for kernel in [\"poly\", \"rbf\", \"sigmoid\"]:\n",
    "    df_svm = df.copy()\n",
    "    print(f\"{kernel}: \",\n",
    "    SVC(kernel=kernel).fit(df_svm[[\"x\", \"y\"]], df_svm[\"InSet\"]).score(df_svm[[\"x\", \"y\"]], df_svm[\"InSet\"])\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feed forward NN (Identity activation)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "df_nn = df.copy()\n",
    "MLPClassifier(hidden_layer_sizes=(100,),activation=\"identity\").fit(df_nn[[\"x\", \"y\"]], df_nn[\"InSet\"]).score(df_nn[[\"x\", \"y\"]], df_nn[\"InSet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cheaty preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "df_nn = df.copy()\n",
    "# Essentially we assign each point a true/false value and feed it to the NN\n",
    "# This is cheating because it should now only ever work for these exact points\n",
    "encoder = OneHotEncoder()\n",
    "encoder.fit(df_nn[[\"x\", \"y\"]])\n",
    "df_nn = pd.DataFrame(encoder.transform(df_nn[[\"x\", \"y\"]]).toarray())\n",
    "df_nn[\"InSet\"] = df[\"InSet\"]\n",
    "print(\"Identity activation: \",\n",
    "    MLPClassifier(hidden_layer_sizes=(100,),activation=\"identity\").fit(df_nn.drop(\"InSet\", axis=1), df_nn[\"InSet\"]).score(df_nn.drop(\"InSet\", axis=1), df_nn[\"InSet\"])\n",
    ")\n",
    "print(\"Logistic activation: \",\n",
    "    MLPClassifier(hidden_layer_sizes=(100,),activation=\"logistic\").fit(df_nn.drop(\"InSet\", axis=1), df_nn[\"InSet\"]).score(df_nn.drop(\"InSet\", axis=1), df_nn[\"InSet\"])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Feed forward NN (Sigmoid activation)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "df_nn = df.copy()\n",
    "MLPClassifier(hidden_layer_sizes=(100,),activation=\"logistic\").fit(df_nn[[\"x\", \"y\"]], df_nn[\"InSet\"]).score(df_nn[[\"x\", \"y\"]], df_nn[\"InSet\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (b)\n",
    "Step function gives True, for everything greater or equal to 0.  \n",
    "A neuron performs $x_1*w_1+x_2*w_2$ for inputs $x_1$ and $x_2$ with weights $w_1,w_2$ unique to the neuron and then applies the activation function to the result.\n",
    "\n",
    "Line 1 $((w_1*0+w_2*1 \\geq 0) = False)$ implies that $w_2$ would have to be negative.  \n",
    "Line 2 $((w_1*1+w_2*1 \\geq 0) = True)$ implies $w_1 \\geq -w_2$.  \n",
    "Last line $((w_1*1 + w_2*0 \\geq 0) = False)$ requires $w_1$ to be negative which is in contradiction to the previous two assertions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-ids-ws23",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
